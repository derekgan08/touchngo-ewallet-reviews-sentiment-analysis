{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Install and Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-play-scraper in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: joblib in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wt\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-play-scraper nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from google_play_scraper import Sort, reviews_all\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\WT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\WT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Scrape User Reviews from Google Play Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews = reviews_all(\n",
    "        \"my.com.tngdigital.ewallet\",\n",
    "        sleep_milliseconds=0, # defaults to 0\n",
    "        lang='en', # defaults to 'en'\n",
    "        country='us', # defaults to 'us'\n",
    "        sort=Sort.NEWEST, # defaults to Sort.MOST_RELEVANT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(app_reviews),columns=['review'])\n",
    "df2 = df.join(pd.DataFrame(df.pop('review').tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = df2[['content', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WT\\AppData\\Local\\Temp\\ipykernel_15668\\1868447951.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df['content'] = reviews_df['content'].astype(str)\n",
      "C:\\Users\\WT\\AppData\\Local\\Temp\\ipykernel_15668\\1868447951.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df['content']= reviews_df['content'].apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "reviews_df['content'] = reviews_df['content'].astype(str)\n",
    "reviews_df['content']= reviews_df['content'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text=[]\n",
    "\n",
    "def extract_reviews(s):\n",
    "    expe = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    return expe.sub(r'',s)\n",
    "\n",
    "for y in reviews_df['content']:\n",
    "    extracted_text.append(str(extract_reviews(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text = []\n",
    "for s in extracted_text:\n",
    "  filtered_text.append(re.sub('[^a-z *]', \"\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WT\\AppData\\Local\\Temp\\ipykernel_15668\\4255706099.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df['content'] = pd.DataFrame(filtered_text)\n"
     ]
    }
   ],
   "source": [
    "reviews_df['content'] = pd.DataFrame(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general_corpus.txt', 'w') as f:\n",
    "  for w in reviews_df['content']:\n",
    "    f.write(\"%s \" % w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = reviews_df[reviews_df['score'] > 3]['content']\n",
    "neg_reviews = reviews_df[reviews_df['score'] < 3]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos_corpus_b4.txt', 'w') as f:\n",
    "  for w in pos_reviews:\n",
    "    f.write(\"%s \" % w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg_corpus_b4.txt', 'w') as f:\n",
    "  for w in neg_reviews:\n",
    "    f.write(\"%s \" % w)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
